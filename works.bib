@inproceedings{ulicny2020tensor,
title={Tensor Reordering for CNN Compression}, 
author={Matej Ulicny and Vladimir A. Krylov and Rozenn Dahyot},
booktitle={ICASSP 2021},
doi={},
note={Github: https://github.com/matej-ulicny/reorder-cnn-compression},
abstract={We show how parameter redundancy in Convolutional Neural Network (CNN) filters can be effectively reduced by pruning in spectral domain. Specifically, the representation extracted via Discrete Cosine Transform (DCT) is more conducive for pruning than the original space. By relying on a combination of weight tensor reshaping and reordering we achieve high levels of layer compression with just minor accuracy loss. Our approach is applied to compress pretrained CNNs and we show that minor additional fine-tuning allows our method to recover the original model performance after a significant parameter reduction. We validate our approach on ResNet-50 and MobileNet-V2 architectures for ImageNet classification task.},
url={https://arxiv.org/pdf/2010.12110.pdf},
year={2021},
eprint={2010.12110},
archivePrefix={arXiv},
primaryClass={cs.LG}
},





@article{10.1145/3403572,
author= {Prado, Miguel De and Su, Jing and Saeed, Rabia and Keller, Lorenzo and Vallez, Noelia and Anderson, Andrew and Gregg, David and Benini, Luca and Llewellynn, Tim and Ouerhani, Nabil and Dahyot, Rozenn and Pazos, Nuria}, 
title= {Bonseyes AI Pipeline—Bringing AI to You: End-to-End Integration of Data, Algorithms, and Deployment Tools}, 
year= {2020}, 
issue_date= {August 2020}, 
publisher= {Association for Computing Machinery}, 
address= {New York, NY, USA},
volume= {1},
number= {4}, 
issn= {2691-1914}, 
url= {https://arxiv.org/pdf/1901.05049.pdf}, 
doi= {10.1145/3403572}, 
journal= {ACM Trans. Internet Things},
month= {aug}, 
articleno= {26}, 
numpages= {25},
abstract = {Next generation of embedded Information and Communication Technology (ICT) systems are interconnected and collaborative systems able to perform autonomous tasks. The remarkable expansion of the embedded ICT market, together with the rise and breakthroughs of Artificial Intelligence (AI), have put the focus on the Edge as it stands as one of the keys for the next technological revolution: the seamless integration of AI in our daily life. However, training and deployment of custom AI solutions on embedded devices require a fine-grained integration of data, algorithms, and tools to achieve high accuracy and overcome functional and non-functional requirements. Such integration requires a high level of expertise that becomes a real bottleneck for small and medium enterprises wanting to deploy AI solutions on the Edge, which, ultimately, slows down the adoption of AI on applications in our daily life.In this work, we present a modular AI pipeline as an integrating framework to bring data, algorithms, and deployment tools together. By removing the integration barriers and lowering the required expertise, we can interconnect the different stages of particular tools and provide a modular end-to-end development of AI products for embedded devices. Our AI pipeline consists of four modular main steps: (i) data ingestion, (ii) model training, (iii) deployment optimization, and (iv) the IoT hub integration. To show the effectiveness of our pipeline, we provide examples of different AI applications during each of the steps. Besides, we integrate our deployment framework, Low-Power Deep Neural Network (LPDNN), into the AI pipeline and present its lightweight architecture and deployment capabilities for embedded devices. Finally, we demonstrate the results of the AI pipeline by showing the deployment of several AI applications such as keyword spotting, image classification, and object detection on a set of well-known embedded platforms, where LPDNN consistently outperforms all other popular deployment frameworks.},
keywords= {deep learning, AI pipeline, keyword spotting, fragmentation}}

,
@inproceedings{chopin:hal-02882043,
TITLE= {{M{\'e}thode d'analyse s{\'e}mantique d'images combinant apprentissage profond et relations structurelles par appariement de graphes}}, 
AUTHOR= {Chopin, J{\'e}r{\'e}my and Fasquel, Jean-Baptiste and Mouch{\`e}re, Harold and Bloch, Isabelle and Dahyot, Rozenn}, 
URL= {https://hal.archives-ouvertes.fr/hal-02882043}, 
BOOKTITLE= {{Rencontres des Jeunes Chercheur$\times$ses en Intelligence Artificielle (RJCIA 2020)}}, 
ADDRESS= {Angers, France}, 
abstract={We propose a method for semantic image segmentation,
combining a deep neural network and spatial relationships
between image regions, encoded in a graph representation
of the scene. Our proposal is based on inexact graph matching, applied to the output of a deep neural network. The
proposed method is evaluated on a public dataset used for
segmentation of images of faces. Preliminary results show
that, in terms of IoU of region bounding boxes, the use of
spatial relationships lead to an improvement of 2.4% in
average, and up to 24.4% for some regions.},
HAL_LOCAL_REFERENCE= {ISISV},
YEAR= {2020}, 
MONTH= {jun},
HAL_ID= {hal-02882043}, 
HAL_VERSION= {v1}}

,
@techreport{DBLP:journals/corr/abs-2001-06570, 
author= {Matej Ulicny and Vladimir A. Krylov and Rozenn Dahyot}, 
title= {Harmonic Convolutional Networks based on Discrete Cosine Transform}, 
journal= {CoRR},
abstract={Convolutional neural networks (CNNs) learn filters in order to capture local correlation patterns in feature space. We propose to learn these filters as combinations of preset spectral filters defined by the Discrete Cosine Transform (DCT). Our proposed DCT-based harmonic blocks replace conventional convolutional layers to produce partially or fully harmonic versions of new or existing CNN architectures. Using DCT energy compaction properties, we demonstrate how the harmonic networks can be efficiently compressed by truncating high-frequency information in harmonic blocks thanks to the redundancies in the spectral domain. We report extensive experimental validation demonstrating benefits of the introduction of harmonic blocks into state-of-the-art CNN models in image classification, object detection and semantic segmentation applications.},
volume= {abs/2001.06570}, 
year= {2020}, 
url= {https://arxiv.org/pdf/2001.06570.pdf}, 
note={Github: https://github.com/matej-ulicny/harmonic-networks},
archivePrefix= {arXiv}, eprint= {2001.06570}, 
timestamp= {Fri, 24 Jan 2020 15:00:57 +0100}, 
biburl= {https://dblp.org/rec/journals/corr/abs-2001-06570.bib},
bibsource= {dblp computer science bibliography, https://dblp.org}}

,
@article{Smile2020, 
note={Github: https://github.com/speed8928/IMELE},
abstract={Estimation of the Digital Surface Model (DSM) and building heights from single-view aerial imagery is a challenging inherently ill-posed problem that we address in this paper by resorting to machine learning. We propose an end-to-end trainable convolutional-deconvolutional deep neural network architecture that enables learning mapping from a single aerial imagery to a DSM for analysis of urban scenes. We perform multisensor fusion of aerial optical and aerial light detection and ranging (Lidar) data to prepare the training data for our pipeline. The dataset quality is key to successful estimation performance. Typically, a substantial amount of misregistration artifacts are present due to georeferencing/projection errors, sensor calibration inaccuracies, and scene changes between acquisitions. To overcome these issues, we propose a registration procedure to improve Lidar and optical data alignment that relies on Mutual Information, followed by Hough transform-based validation step to adjust misregistered image patches. We validate our building height estimation model on a high-resolution dataset captured over central Dublin, Ireland: Lidar point cloud of 2015 and optical aerial images from 2017. These data allow us to validate the proposed registration procedure and perform 3D model reconstruction from single-view aerial imagery. We also report state-of-the-art performance of our proposed architecture on several popular DSM estimation datasets},
doi= {10.3390/rs12172719}, 
url= {https://www.mdpi.com/2072-4292/12/17/2719/pdf}, 
year= {2020}, 
month= {August}, 
publisher= {{MDPI} {AG}}, 
volume= {12}, 
number= {17}, 
pages= {2719},
author= {C.-J. Liu and V. A. Krylov and P. Kane and G. Kavanagh and R. Dahyot}, 
title= {IM2ELEVATION: Building Height Estimation from Single-View Aerial Imagery}, 
journal= {Remote Sensing}}
,

@inproceedings{10.1145/3424636.3426904, 
author= {Carrigan, Emma and Zibrek, Katja and Dahyot, Rozenn and McDonnell, Rachel}, 
title= {Investigating Perceptually Based Models to Predict Importance of Facial Blendshapes}, 
year= {2020},
 isbn= {9781450381710}, 
 publisher= {Association for Computing Machinery},
 address= {New York, NY, USA},
 url= {https://roznn.github.io/facial-blendshapes/MIG2020.pdf}, 
 note={Github: https://github.com/Roznn/facial-blendshapes},
 doi= {10.1145/3424636.3426904}, 
 abstract= {Blendshape facial rigs are used extensively in the industry for facial 
 animation of virtual humans. However, storing and manipulating large numbers of facial 
 meshes is costly in terms of memory and computation for gaming applications, yet the relative perceptual importance of blendshapes has not yet been investigated.
 Research in Psychology and Neuroscience has shown that our brains process faces differently than other objects, so we postulate that 
 the perception of facial expressions will be feature-dependent rather than based purely on the amount of movement required to make the expression. 
 In this paper, we explore the noticeability of blendshapes under different activation levels, and present new perceptually based models to predict
 perceptual importance of blendshapes. The models predict visibility based on commonly-used geometry and image-based metrics. },
 booktitle= {Motion, Interaction and Games}, 
 articleno= {2}, 
 numpages= {6}, 
 note={Github: https://roznn.github.io/facial-blendshapes/},
 keywords= {blendshapes, perception, action units, linear model}, 
 location= {Virtual Event, SC, USA}, series= {MIG '20}}
,
@inproceedings{DBLP:journals/corr/abs-2006-09208, 
author= {Hana Alghamdi and  Rozenn Dahyot}, 
title= {Iterative Nadaraya-Watson Distribution Transfer for Colour Grading}, 
booktitle= {2020 IEEE 22nd International Workshop on Multimedia Signal Processing (MMSP)},
volume= {},
pages={1-6},
abstract={We propose a new method with Nadaraya-Watson that maps one N-dimensional distribution to another, taking into account available information about correspondences. We extend the 2D/3D problem to higher dimensions by encoding overlapping neighborhoods of data points and solve the high-dimensional problem in 1D space using an iterative projection approach. To show the potentials of this mapping, we apply it to colour transfer between two images that exhibit overlapped scenes. Experiments show quantitative and qualitative improvements over the previous state of the art colour transfer methods.},
note={Github: https://github.com/leshep/INWDT},
doi={10.1109/MMSP48831.2020.9287097},
year= {2020}, 
url= {https://arxiv.org/pdf/2006.09208.pdf}}
,
@inproceedings{DBLP:journals/corr/abs-2005-09015,
author= {Hana Alghamdi and Rozenn Dahyot}, 
title= {Patch based Colour Transfer using {SIFT} Flow},
booktitle= {Irish Machine Vision and Image Processing (IMVIP 2020)},
volume= {abs/2005.09015},
year= {2020},
abstract={We propose a new colour transfer method with Optimal Transport (OT) to transfer the colour of a sourceimage to match the colour of a target image of the same scene that may exhibit large motion changes betweenimages. By definition OT does not take into account any available information about correspondences whencomputing the optimal solution. To tackle this problem we propose to encode overlapping neighborhoodsof pixels using both their colour and spatial correspondences estimated using motion estimation. We solvethe high dimensional problem in 1D space using an iterative projection approach. We further introducesmoothing as part of the iterative algorithms for solving optimal transport namely Iterative DistributionTransport (IDT) and its variant the Sliced Wasserstein Distance (SWD). Experiments show quantitative andqualitative improvements over previous state of the art colour transfer methods.},
url= {https://arxiv.org/pdf/2005.09015.pdf}, 
note={Best Paper Award, Book Open Access http://research.thea.ie/handle/20.500.12065/3429},
archivePrefix= {arXiv}, 
eprint= {2005.09015},
timestamp= {Fri, 22 May 2020 16:21:29 +0200},
biburl= {https://dblp.org/rec/journals/corr/abs-2005-09015.bib},
bibsource= {dblp computer science bibliography, https://dblp.org}}
,

@inproceedings{ReemIMVIP2020,
author= {R. Aljuaidi and R. Dahyot}, 
title= {Efficient Visual Place Retrieval System Using Google Street View},
booktitle= {Irish Machine Vision and Image Processing (IMVIP 2020)},
year= {2020},
abstract={},
url= {http://research.thea.ie/handle/20.500.12065/3429}, 
note={Book Open Access http://research.thea.ie/handle/20.500.12065/3429},
}
,
@inproceedings{YadavIMVIP2020,
author= {R. Yadav, A. Samir, H. Rashed, S. Yogamani and R. Dahyot}, 
title= {CNN based Color and Thermal Image Fusion for Object Detection in Automated Driving},
booktitle= {Irish Machine Vision and Image Processing (IMVIP 2020)},
year= {2020},
abstract={},
url= {http://research.thea.ie/handle/20.500.12065/3429}, 
note={Book Open Access http://research.thea.ie/handle/20.500.12065/3429},
}
,

@INPROCEEDINGS{9286611, 
author= {J. {Chopin} and J.B. {Fasquel} and H. {Mouchère} and R. {Dahyot} and I. {Bloch}}, 
booktitle= {2020 Tenth International Conference on Image Processing Theory, Tools and Applications (IPTA)},
title= {Semantic image segmentation based on spatial relationships and inexact graph matching}, 
year= {2020},
volume= {}, 
number= {}, 
pages= {1-6}, 
abstract= {We propose a method for semantic image segmentation, combining a deep neural network and spatial relationships between image regions, encoded in a graph representation of the scene. Our proposal is based on inexact graph matching, formulated as a quadratic assignment problem applied to the output of the neural network. The proposed method is evaluated on a public dataset used for segmentation of images of faces, and compared to the U-Net deep neural network that is widely used for semantic segmentation. Preliminary results show that our approach is promising. In terms of Intersection-over-Union of region bounding boxes, the improvement is of 2.4% in average, compared to U-Net, and up to 24.4% for some regions. Further improvements are observed when reducing the size of the training dataset (up to 8.5% in average).}, 
keywords= {Computer vision;Deep learning;Inexact graph matching;Quadratic assignment problem},
doi= {10.1109/IPTA50016.2020.9286611}, 
url={https://hal.archives-ouvertes.fr/hal-02916165/file/2020IPTA.pdf},
ISSN= {2154-512X}, month= {Nov}}
,
@INPROCEEDINGS{9188213,
  author={A. {Anderson} and J. {Su} and R. {Dahyot} and D. {Gregg}},
  booktitle={2019 International Conference on High Performance Computing   Simulation (HPCS)}, 
  title={Performance-Oriented Neural Architecture Search}, 
  year={2019},
  eprint= {2001.02976}, 
  archivePrefix= {arXiv}, 
  volume={},
  number={},
  pages={177-184},
  doi={10.1109/HPCS48598.2019.9188213}}
  ,
  
@inproceedings{DBLP:journals/corr/abs-1905-12678,
author    = {Rozenn Dahyot and
               Hana Alghamdi and
               Mair{\'{e}}ad Grogan},
  title     = {Entropic Regularisation of Robust Optimal Transport},
  booktitle  = {Irish Machine Vision and Image Processing conference 2019},
  volume    = {abs/1905.12678},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.12678},
  archivePrefix = {arXiv},
doi={http://doi.org/10.21427/w611-mb37},
  eprint    = {1905.12678},
  timestamp = {Mon, 03 Jun 2019 13:42:33 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1905-12678},
  bibsource = {dblp computer science bibliography, https://dblp.org},
},
@techreport{DBLP:journals/corr/abs-1905-00135,
  author    = {Matej Ulicny and
               Vladimir A. Krylov and
               Rozenn Dahyot},
  title     = {Harmonic Networks with Limited Training Samples},
  journal   = {CoRR},
  volume    = {abs/1905.00135},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.00135},
  archivePrefix = {arXiv},
  eprint    = {1905.00135},
  timestamp = {Mon, 27 May 2019 13:15:00 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1905-00135},
  bibsource = {dblp computer science bibliography, https://dblp.org}
},
@inproceedings{DBLP:journals/corr/abs-1901-05049, 
author= {Miguel de Prado and
               Jing Su and
               Rozenn Dahyot and
               Rabia Saeed and
               Lorenzo Keller and
               Noelia V{\'{a}}llez}, title= {{AI} Pipeline - bringing {AI} to you. End-to-end integration of data,
               algorithms and deployment tools}, booktitle= {HiPEAC 2019 workshop Emerging Deep Learning Accelerator}, volume= {abs/1901.05049}, year= {2019}, url= {http://arxiv.org/abs/1901.05049}, archivePrefix= {arXiv}, eprint= {1901.05049}, timestamp= {Fri, 01 Feb 2019 13:39:59 +0100}, biburl= {https://dblp.org/rec/bib/journals/corr/abs-1901-05049}, bibsource= {dblp computer science bibliography, https://dblp.org}}

,
@article{AHMAD2019110, title= {Automatic detection of passable roads after floods in remote sensed and social media data}, journal= {Signal Processing: Image Communication}, volume= {74}, pages= {110 - 118}, year= {2019}, issn= {0923-5965}, doi= {https://doi.org/10.1016/j.image.2019.02.002}, url= {http://www.sciencedirect.com/science/article/pii/S0923596518311536}, author= {Kashif Ahmad and Konstantin Pogorelov and Michael Riegler and Olga Ostroukhova and Pål Halvorsen and Nicola Conci and Rozenn Dahyot}, keywords= {Flood detection, Convolutional neural networks, Natural disasters, Social media, Satellite imagery, Multimedia indexing and retrieval}, abstract= {This paper addresses the problem of floods classification and floods aftermath detection based on both social media and satellite imagery. Automatic detection of disasters such as floods is still a very challenging task. The focus lies on identifying passable routes or roads during floods. Two novel solutions are presented, which were developed for two corresponding tasks at the MediaEval 2018 benchmarking challenge. The tasks are (i) identification of images providing evidence for road passability and (ii) differentiation and detection of passable and non-passable roads in images from two complementary sources of information. For the first challenge, we mainly rely on object and scene-level features extracted through multiple deep models pre-trained on the ImageNet and Places datasets. The object and scene-level features are then combined using early, late and double fusion techniques. To identify whether or not it is possible for a vehicle to pass a road in satellite images, we rely on Convolutional Neural Networks and a transfer learning-based classification approach. The evaluation of the proposed methods is carried out on the large-scale datasets provided for the benchmark competition. The results demonstrate significant improvement in the performance over the recent state-of-art approaches.}}

,
@inproceedings{IMVIP2019Albluwi, title= {Denoising RENOIR Image Dataset with DBSR}, author= {Fatma Albluwi, Vladimir A. Krylov and R. Dahyot}, booktitle= {Irish Machine Vision and Image Processing (IMVIP 2019)}, address= {Technological University Dublin}, month= {28-30 August}, year= {2019}, pages= {76-79}, volume= {ISBN 978-0-9934207-4-0}}

,
@inproceedings{BMVC2019, title= {Harmonic Networks for Image Classification}, author= {M. Ulicny and V. Krylov and R. Dahyot}, booktitle= {British Machine Vision Conference (BMVC)}, address= {Cardiff UK}, month= {9-12 September}, year= {2019}}

,
@INPROCEEDINGS{8902831, author= {M. {Ulicny} and V. A. {Krylov} and R. {Dahyot}}, booktitle= {2019 27th European Signal Processing Conference (EUSIPCO)}, title= {Harmonic Networks with Limited Training Samples}, year= {2019}, volume= {}, number= {}, pages= {1-5}, keywords= {Lapped Discrete Cosine Transform;harmonic network;convolutional filter;limited data}, doi= {10.23919/EUSIPCO.2019.8902831}, ISSN= {2219-5491}, month= {Sep.}}

,
@article{GROGAN2019, title= {L2 Divergence for robust colour transfer}, journal= {Computer Vision and Image Understanding}, year= {2019}, issn= {1077-3142}, doi= {https://doi.org/10.1016/j.cviu.2019.02.002}, url= {http://www.sciencedirect.com/science/article/pii/S1077314219300177}, author= {Mairead Grogan and Rozenn Dahyot}, keywords= {Colour Transfer, L2 Registration, Re-colouring, Colour Grading}, abstract= {Optimal Transport (OT) is a very popular framework for performing colour transfer in images and videos. We have proposed an alternative framework where the cost function used for inferring a parametric transfer function is defined as the robust L2 divergence between two probability density functions (Grogan and Dahyot, 2015). In this paper, we show that our approach combines many advantages of state of the art techniques and outperforms many recent algorithms as measured quantitatively with standard quality metrics, and qualitatively using perceptual studies (Grogan and Dahyot, 2017). Mathematically, our formulation is presented in contrast to the OT cost function that shares similarities with our cost function. Our formulation, however, is more flexible as it allows colour correspondences that may be available to be taken into account and performs well despite potential occurrences of correspondence outlier pairs. Our algorithm is shown to be fast, robust and it easily allows for user interaction providing freedom for artists to fine tune the recoloured images and videos (Grogan et al., 2017).}}

,
@INPROCEEDINGS{8904931, author= {R. {Aljuaidi} and J. {Su} and R. {Dahyot}}, booktitle= {2019 30th Irish Signals and Systems Conference (ISSC)}, title= {Mini-Batch VLAD for Visual Place Retrieval}, year= {2019}, volume= {}, number= {}, pages= {1-6}, keywords= {feature extraction;content-based image retrieval;image processing}, doi= {10.1109/ISSC.2019.8904931}, ISSN= {2688-1446}, month= {June}}

,
@InProceedings{10.1007/978-3-030-13453-2_7, author= {Krylov, Vladimir A.
and Dahyot, Rozenn}, editor= {Alzate, Carlos
and Monreale, Anna
and Assem, Haytham
and Bifet, Albert
and Buda, Teodora Sandra
and Caglayan, Bora
and Drury, Brett
and Garc{\'i}a-Mart{\'i}n, Eva
and Gavald{\`a}, Ricard
and Kramer, Stefan
and Lavesson, Niklas
and Madden, Michael
and Molloy, Ian
and Nicolae, Maria-Irina
and Sinn, Mathieu}, doi= {https://doi.org/10.1007/978-3-030-13453-2_7}, title= {Object Geolocation from Crowdsourced Street Level Imagery}, booktitle= {ECML PKDD 2018 Workshops}, year= {2019}, publisher= {Springer International Publishing}, address= {Cham}, pages= {79--83}, abstract= {We explore the applicability and limitations of a state-of-the-art object detection and geotagging system [4] applied to crowdsourced image data. Our experiments with imagery from Mapillary crowdsourcing platform demonstrate that with increasing amount of images, the detection accuracy is getting close to that obtained with high-end street level data. Nevertheless, due to excessive camera position noise, the estimated geolocation (position) of the detected object is less accurate on crowdsourced Mapillary imagery than with high-end street level imagery obtained by Google Street View.}, isbn= {978-3-030-13453-2}}

,
@INPROCEEDINGS{8902611, author= {H. {Alghamdi} and M. {Grogan} and R. {Dahyot}}, booktitle= {2019 27th European Signal Processing Conference (EUSIPCO)}, title= {Patch-Based Colour Transfer with Optimal Transport}, year= {2019}, volume= {}, number= {}, pages= {1-5}, keywords= {optimal transport;colour transfer;image enhancement;JPEG compression blocks}, doi= {10.23919/EUSIPCO.2019.8902611}, ISSN= {2219-5491}, month= {Sep.}}

,
@INPROCEEDINGS{8903000, author= {F. {Albluwi} and V. A. {Krylov} and R. {Dahyot}}, booktitle= {2019 27th European Signal Processing Conference (EUSIPCO)}, title= {Super-Resolution on Degraded Low-Resolution Images Using Convolutional Neural Networks}, year= {2019}, volume= {}, number= {}, pages= {1-5}, keywords= {Image super-resolution;image deblurring;deep learning;CNN}, doi= {10.23919/EUSIPCO.2019.8903000}, ISSN= {2219-5491}, month= {Sep.}}

,
@inproceedings{Bhatia2019, title= {Using WGAN for Improving Imbalanced
 Classification Performance}, author= {S. Bhatia and R. Dahyot}, booktitle= {27th Irish Conference on Artificial Intelligence and Cognitive Science}, address= {Galway, Ireland}, issn= {1613-0073}, year= {2019}, editor= {Edward Curry and Mark Keane and Adegboyega Ojo and Dhaval Salwala}, pages= {365-375}, url= {http://ceur-ws.org/Vol-2563/aics_34.pdf}}

,
@article{Krylov_2018,
	doi = {10.3390/rs10050661},
	url = {https://doi.org/10.3390%2Frs10050661},
	year = 2018,
	month = {apr},
	publisher = {{MDPI} {AG}},
	volume = {10},
	number = {5},
	pages = {661},
	author = {Vladimir Krylov and Eamonn Kenny and Rozenn Dahyot},
	title = {Automatic Discovery and Geotagging of Objects from Street View Imagery},
	journal = {Remote Sensing}
},
@inproceedings{LiuIMVIP2018, title= {3D point cloud segmentation using GIS}, author= {C.-J. Liu, K. Vladimir and R. Dahyot}, booktitle= {Irish Machine Vision and Image Processing conference (IMVIP 2018)}, year= {2018}, volume= {e-book of proceedings with ISBN 978-0-9934207-3-3}, url= {http://hdl.handle.net/2262/89508}, address= {Ulster University, Northern Ireland}}

,
@techreport{DBLP:journals/corr/abs-1812-03205, author= {Matej Ulicny and
               Vladimir A. Krylov and
               Rozenn Dahyot}, title= {Harmonic Networks: Integrating Spectral Information into CNNs}, journal= {CoRR}, volume= {abs/1812.03205}, year= {2018}, url= {http://arxiv.org/abs/1812.03205}, archivePrefix= {arXiv}, eprint= {1812.03205}, timestamp= {Tue, 01 Jan 2019 15:01:25 +0100}, biburl= {https://dblp.org/rec/bib/journals/corr/abs-1812-03205}, bibsource= {dblp computer science bibliography, https://dblp.org}}

,
@INPROCEEDINGS{8516983, author= {F. Albluwi and V. A. Krylov and R. Dahyot}, booktitle= {2018 IEEE 28th International Workshop on Machine Learning for Signal Processing (MLSP)}, title= {Image Deblurring and Super-Resolution Using Deep Convolutional Neural Networks}, year= {2018}, volume= {}, number= {}, pages= {1-6}, keywords= {convolution;image reconstruction;image resolution;image restoration;learning (artificial intelligence);neural nets;image deblurring;deep convolutional neural networks;multiple high performance algorithms;high-resolution images;low-resolution image input;deep learning algorithms;low-resolution images;deep learning approach;blurred low resolution images;super-resolution convolutional neural network;Training;Image resolution;Pipelines;Image reconstruction;Signal resolution;Feature extraction;Convolutional neural networks;Image super-resolution;deblurring;deep learning;convolutional neural networks}, doi= {10.1109/MLSP.2018.8516983}, ISSN= {1551-2541}, month= {Sept}}

,
@INPROCEEDINGS{8451458, author= {V. A. Krylov and R. Dahyot}, booktitle= {2018 25th IEEE International Conference on Image Processing (ICIP)}, title= {Object Geolocation Using MRF Based Multi-Sensor Fusion}, year= {2018}, volume= {}, number= {}, pages= {2745-2749}, keywords= {Laser radar;Three-dimensional displays;Cameras;Geology;Roads;Pipelines;Image segmentation;Object geolocation;street level imagery;LiDAR data;Markov random fields;traffic lights}, doi= {10.1109/ICIP.2018.8451458}, ISSN= {2381-8549}, month= {Oct}}

,
@article{GROGAN2018452, title= {Shape registration with directional data}, journal= {Pattern Recognition}, volume= {79}, pages= {452 - 466}, year= {2018}, issn= {0031-3203}, doi= {https://doi.org/10.1016/j.patcog.2018.02.021}, url= {http://www.sciencedirect.com/science/article/pii/S003132031830075X}, author= {Mairead Grogan and Rozenn Dahyot}, keywords= {Shape registration, Directional information, Von Mises-Fisher,  registration}}

,
@techreport{DBLP:journals/corr/abs-1708-08417,
  author    = {Vladimir A. Krylov and
               Eamonn Kenny and
               Rozenn Dahyot},
  title     = {Automatic Discovery and Geotagging of Objects from Street View Imagery},
  journal   = {CoRR},
  volume    = {abs/1708.08417},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.08417},
  archivePrefix = {arXiv},
  eprint    = {1708.08417},
  timestamp = {Tue, 17 Sep 2019 14:15:16 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-08417},
  bibsource = {dblp computer science bibliography, https://dblp.org}
},
@inproceedings{Llewellynn:2017:BPO:3075564.3076259, author= {Llewellynn, Tim and Fern\'{a}ndez-Carrobles, M. Milagro and Deniz, Oscar and Fricker, Samuel and Storkey, Amos and Pazos, Nuria and Velikic, Gordana and Leufgen, Kirsten and Dahyot, Rozenn and Koller, Sebastian and Goumas, Georgios and Leitner, Peter and Dasika, Ganesh and Wang, Lei and Tutschku, Kurt}, title= {BONSEYES: Platform for Open Development of Systems of Artificial Intelligence: Invited Paper}, booktitle= {Proceedings of the Computing Frontiers Conference}, series= {CF'17}, year= {2017}, isbn= {978-1-4503-4487-6}, location= {Siena, Italy}, pages= {299--304}, numpages= {6}, url= {http://doi.acm.org/10.1145/3075564.3076259}, doi= {https://doi.org/10.1145/3075564.3076259}, acmid= {3076259}, publisher= {ACM}, address= {New York, NY, USA}, keywords= {Data marketplace, Deep Learning, Internet of things, Smart Cyber-Physical Systems}}

,
@inproceedings{MatejIMVIP2017, title= {On Using CNN with Compressed (DCT Based) Image Data}, author= {M. Ulicny and R. Dahyot}, booktitle= {Irish Machine Vision and Image Processing conference (IMVIP 2017)}, year= {2017}, pages= {44-51}, volume= {e-book of proceedings with ISBN 978-0-9934207-2-6}, url= {http://eprints.maynoothuniversity.ie/8841/}, address= {Maynooth University}}

,
@article{BulbulCAVW2016, author= {Bulbul, Abdullah and Dahyot, Rozenn}, title= {Populating virtual cities using social media}, journal= {Computer Animation and Virtual Worlds}, volume= {28}, number= {5}, pages= {e1742}, year= {2017}, keywords= {computer animation, crowd simulations, social media, virtual worlds}, doi= {http://doi.org/10.1002/cav.1742}, url= {https://onlinelibrary.wiley.com/doi/abs/10.1002/cav.1742}, eprint= {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cav.1742}, abstract= {Abstract: We propose to automatically populate geo‐located virtual cities by harvesting and analyzing online contents shared on social networks and websites. We show how pose and motion paths of agents can be realistically rendered using information gathered from social media. 3D cities are automatically generated using open‐source information available online. To provide our final rendering of both static and dynamic urban scenes, we use Unreal game engine.}}

,
@techreport{DBLP:journals/corr/GroganD17, author= {Mair{\'{e}}ad Grogan and Rozenn Dahyot}, title= {Robust Registration of Gaussian Mixtures for Colour Transfer}, journal= {CoRR}, volume= {abs/1705.06091}, year= {2017}, url= {http://arxiv.org/abs/1705.06091}, archivePrefix= {arXiv}, eprint= {1705.06091}, timestamp= {Wed, 07 Jun 2017 14:41:30 +0200}, biburl= {https://dblp.org/rec/bib/journals/corr/GroganD17}, bibsource= {dblp computer science bibliography, https://dblp.org}}

,
@article{BulbulCAG2016, title= {Social media based 3D visual popularity }, journal= {Computers \& Graphics }, volume= {63}, number= {}, pages= {28 - 36}, year= {2017}, note= {}, issn= {0097-8493}, doi= {https://doi.org/10.1016/j.cag.2017.01.005}, url= {http://www.sciencedirect.com/science/article/pii/S0097849317300146}, author= {Abdullah Bulbul and Rozenn Dahyot}, keywords= {3D cities }, abstract= {Abstract: This paper proposes to use a geotagged virtual world for the visualization of people’s visual interest and their sentiment as captured from their social network activities. Using mobile devices, people widely share their experiences and the things they find interesting through social networks. We experimentally show that accumulating information over a period of time from multiple social network users allows to efficiently map and visualize popular landmarks as found in cities such as Rome in Italy and Dublin in Ireland. The proposed approach is also sensitive to temporal and spatial events that attract visual attention. We visualize the calculated popularity on 3D virtual cities using game engine technologies. }}

,
@techreport{Drone2017, title= {Trinity College Dublin Drone Survey Dataset}, author= {J. Byrne and J. Connelly and  J. Su and V. Krylov and M. Bourke and D. Moloney and R. Dahyot}, school= {School of Computer Science and Statistics, Trinity College Dublin}, year= {2017}, url= {http://hdl.handle.net/2262/81836}}

,
@inproceedings{Grogan:2017:UII:3150165.3150171, author= {Grogan, Mair{\'e}ad and Dahyot, Rozenn and Smolic, Aljosa}, title= {User Interaction for Image Recolouring Using L2}, booktitle= {Proceedings of the 14th European Conference on Visual Media Production (CVMP 2017)}, series= {CVMP 2017}, year= {2017}, isbn= {978-1-4503-5329-8}, location= {London, United Kingdom}, pages= {6:1--6:10}, articleno= {6}, numpages= {10}, note= {Awarded best paper}, url= {http://doi.acm.org/10.1145/3150165.3150171}, doi= {https://doi.org/10.1145/3150165.3150171}, acmid= {3150171}, publisher= {ACM}, address= {New York, NY, USA}, keywords= {L2 Registration, Colour transfer, palette based image recoloring}}

,
@InProceedings{DiECCV2016, author= {Di, Xinhan and Dahyot, Rozenn and Prasad, Mukta}, editor= {Hua, Gang and J{\'e}gou, Herv{\'e}}, title= {Deep Shape from a Low Number of Silhouettes}, booktitle= {Computer Vision -- ECCV 2016 Workshops}, year= {2016}, publisher= {Springer International Publishing}, address= {Cham}, pages= {251--265}, abstract= {Despite strong progress in the field of 3D reconstruction from multiple views, holes on objects, transparency of objects and textureless scenes, continue to be open challenges. On the other hand, silhouette based reconstruction techniques ease the dependency of 3d reconstruction on image pixels but need a large number of silhouettes to be available from multiple views. In this paper, a novel end to end pipeline is proposed to produce high quality reconstruction from a low number of silhouettes, the core of which is a deep shape reconstruction architecture. Evaluations on ShapeNet [1] show good quality of reconstruction compared with ground truth.}, isbn= {978-3-319-49409-8}, url= {https://link.springer.com/chapter/10.1007/978-3-319-49409-8_21}, doi= {https://doi.org/10.1007/978-3-319-49409-8}}

,
@inproceedings{GroganIMVIP2016, title= {Recent techniques for (re)colouring}, author= {M. Grogan and J. Carvalho and R. Dahyot}, booktitle= {Irish Machine Vision and Image Processing Conference (IMVIP 2016)}, month= {August}, address= {Galway, Ireland}, year= {2016}, url= {http://hdl.handle.net/10379/6136}}

,
@article{ArellanoPR2015, title= {Robust ellipse detection with Gaussian mixture models}, journal= {Pattern Recognition}, volume= {58}, pages= {12 - 26}, year= {2016}, issn= {0031-3203}, doi= {https://doi.org/10.1016/j.patcog.2016.01.017}, url= {http://www.sciencedirect.com/science/article/pii/S0031320316000388}, author= {Claudia Arellano and Rozenn Dahyot}, keywords= {Ellipse detection, L2 distance, GMM, Parameter estimation}}

,
@inproceedings{BulbulIMVIP2015, title= {3D Reconstruction of Reflective Spherical Surfaces from Multiple Images}, author= {A. Bulbul and M. Grogan and R. Dahyot}, booktitle= {Irish Machine Vision and Image Processing Conference (IMVIP 2015)}, month= {August}, year= {2015}, address= {Dublin, Ireland}, url= {http://hdl.handle.net/2262/74714}}

,
@inproceedings{XiaIMVIP2015, title= {Hand Hygiene Poses Recognition with RGB-D Videos}, author= {B. Xia and R. Dahyot and J. Ruttle and D. Caulfield and G. Lacey}, booktitle= {Irish Machine Vision and Image Processing Conference (IMVIP 2015)}, month= {August}, address= {Dublin, Ireland}, year= {2015}, url= {http://hdl.handle.net/2262/74714}}

,
@inproceedings{DahyotIWCIM2015, title= {Information visualisation for social media analytics}, author= {R. Dahyot and C. Brady and C. Bourges and A. Bulbul}, booktitle= {2015 International Workshop on Computational Intelligence for Multimedia Understanding (IWCIM)}, keywords= {Global Positioning System;data visualisation;rendering (computer graphics);social networking (online);GPS;audio visual rendering;dataset visualization;geolocated datasets;information visualisation;location information;sentiment extraction;social media analytics;social networks;timestamp;Geology;Google;Heating;Media;Silicon;Visualization;Social Media Analytics;Visualisation}, address= {Prague, Czech Republic}, month= {29-30 October}, year= {2015}, url= {https://ieeexplore.ieee.org/document/7347082/}, doi= {https://doi.org/10.1109/IWCIM.2015.7347082}}

,
@INPROCEEDINGS{GroganEusipco2015, title= {L2 Registration for Colour Transfer}, author= {M. Grogan and M. Prasad and R. Dahyot}, booktitle= {European Signal Processing Conference (Eusipco)}, address= {Nice France}, month= {September}, year= {2015}, doi= {http://doi.org/10.1109/EUSIPCO.2015.7362799}, url= {https://ieeexplore.ieee.org/document/7362799/}, eprint= {https://www.eurasip.org/Proceedings/Eusipco/Eusipco2015/papers/1570102575.pdf}}

,
@inproceedings{GroganCVMP2015, author= {Grogan, Mairead and Dahyot, Rozenn}, title= {L2 Registration for Colour Transfer in Videos}, booktitle= {Proceedings of the 12th European Conference on Visual Media Production}, series= {CVMP '15}, year= {2015}, isbn= {978-1-4503-3560-7}, location= {London, United Kingdom}, pages= {16:1--16:1}, articleno= {16}, numpages= {1}, url= {http://doi.acm.org/10.1145/2824840.2824862}, acmid= {2824862}, publisher= {ACM}, address= {New York, NY, USA}, doi= {http://doi.org/10.1145/2824840.2824862}}

,
@inproceedings{BulbulCVMP2015, author= {Bulbul, Abdullah and Dahyot, Rozenn}, title= {Social Media Based 3D Modeling and Visualization}, booktitle= {Proceedings of the 12th European Conference on Visual Media Production}, series= {CVMP '15}, year= {2015}, isbn= {978-1-4503-3560-7}, location= {London, United Kingdom}, pages= {20:1--20:1}, articleno= {20}, numpages= {1}, url= {http://doi.acm.org/10.1145/2824840.2824860}, doi= {https://doi.org/10.1145/2824840.2824860}, acmid= {2824860}, publisher= {ACM}, address= {New York, NY, USA}}

,
@inproceedings{graisearchIMVIP2014, title= {An Architecture for Social Media Summarisation}, author= {Z. Zdziarski and J. Mitchell and P. Houdyer and D. Johnson and C. Bourges and R. Dahyot}, booktitle= {Irish Machine Vision and Image Processing Conference (IMVIP 2014)}, address= {Derry-Londonderry, Northern Ireland}, pages= {187-188}, year= {2014}, month= {27-29 August}, url= {http://hdl.handle.net/2262/71411}}

,
@INPROCEEDINGS{Zdziarski:SIU:2014, author= {Zdziarski, Z. and Dahyot, R.}, booktitle= {Signal Processing and Communications Applications Conference (SIU), 2014 22nd}, title= {Extension of GBVS to 3D media}, year= {2014}, month= {April}, pages= {2296-2300}, keywords= {computer vision;object tracking;2D displays;3D media;GBVS algorithm;GBVS extension;eye tracking technologies;graph-based visual saliency algorithm;Algorithm design and analysis;Computational modeling;Conferences;Signal processing algorithms;Stereo image processing;Three-dimensional displays;Visualization;3D media;Visual saliency}, doi= {http://doi.org/10.1109/SIU.2014.6830723}}

,
@inproceedings{ICPR2014Dahyot, author= {R. Dahyot}, booktitle= {2014 22nd International Conference on Pattern Recognition}, title= {GR2T vs L2E with Nuisance Scale}, year= {2014}, volume= {}, number= {}, pages= {3857-3861}, keywords= {Radon transforms;regression analysis;GR2T;L2E;generalized relaxed Radon transform;nuisance scale;regression analysis;robust parameter estimation;scale parameter;Equations;Estimation;Mathematical model;Noise;Pattern recognition;Robustness;Transforms}, doi= {http://doi.org/10.1109/ICPR.2014.662}, ISSN= {1051-4651}, month= {Aug}}

,
@inproceedings{GroganIMVIP2014, title= {Mesh from Depth Images Using GR2T}, author= {M. Grogan and R. Dahyot}, booktitle= {Irish Machine Vision and Image Processing Conference}, address= {Derry-Londonderry, Northern Ireland}, pages= {15-20}, month= {27-29 August}, year= {2014}, url= {http://hdl.handle.net/2262/71411}}

,
@inproceedings{graisearchCIMU2014, title= {On summarising the 'here and now' of social videos for smart mobile browsing}, address= {Paris, France}, month= {1-2 Nov.}, year= {2014}, author= {Z. Zdziarski and C. Bourgès and J. Mitchell and P. Houdyer and D. Johnson and R. Dahyot}, booktitle= {2014 International Workshop on Computational Intelligence for Multimedia Understanding (IWCIM)}, keywords= {mobile computing;social networking (online);video retrieval;video signal processing;Tapastreet;mobile platforms;smart mobile browsing;smart processing;social networks;social sites;social video summarisation;visual content;visual data;visual media;Media;Pipelines;Social network services;Streaming media;Transform coding;Videos;Visualization;Blur Detection;MPEG Codec;Social Media;Video Summarisation;Web Harvesting}, doi= {http://doi.org/10.1109/IWCIM.2014.7008797}, ISSN= {}}

,
@article{RuttlePRL2014, title= {Robust shape from depth images with GR2T}, journal= {Pattern Recognition Letters}, volume= {50}, pages= {43 - 54}, year= {2014}, note= {Depth Image Analysis}, issn= {0167-8655}, doi= {https://doi.org/10.1016/j.patrec.2014.01.016}, url= {http://www.sciencedirect.com/science/article/pii/S0167865514000300}, author= {Jonathan Ruttle and Claudia Arellano and Rozenn Dahyot}, keywords= {Shape from depth, Generalised Relaxed Radon Transform (GRT), Noise modelling}}

,
@article{DSP2013Dahyot, title= {Bayesian 3D shape from silhouettes}, journal= {Digital Signal Processing}, volume= {23}, number= {6}, pages= {1844 - 1855}, year= {2013}, issn= {1051-2004}, doi= {https://doi.org/10.1016/j.dsp.2013.06.007}, url= {http://www.sciencedirect.com/science/article/pii/S1051200413001358}, author= {Donghoon Kim and Jonathan Ruttle and Rozenn Dahyot}, keywords= {3D reconstruction from multiple view images, Shape-from-silhouettes, Kernel density estimates, K-nearest neighbours, Principal component analysis}}

,
@article{PR2012Dahyot, title= {Generalised relaxed Radon transform (GR2T) for robust inference}, journal= {Pattern Recognition}, volume= {46}, number= {3}, pages= {788 - 794}, year= {2013}, issn= {0031-3203}, doi= {https://doi.org/10.1016/j.patcog.2012.09.026}, url= {http://www.sciencedirect.com/science/article/pii/S0031320312004347}, author= {Rozenn Dahyot and Jonathan Ruttle}, keywords= {Generalised Radon transform, Hough transform, Robust inference, M-estimator, Generalised projection based M-estimator}}

,
@inproceedings{Zdziarski:2013:ACM:SAP, author= {Zdziarski, Z. and Dahyot, R.}, title= {On Creating a 2D \& 3D Visual Saliency Dataset}, booktitle= {Proceedings of the ACM Symposium on Applied Perception}, series= {SAP '13}, year= {2013}, isbn= {978-1-4503-2262-1}, location= {Dublin, Ireland}, pages= {132--132}, numpages= {1}, url= {http://doi.acm.org/10.1145/2492494.2501889}, doi= {http://doi.org/10.1145/2492494.2501889}, acmid= {2501889}, publisher= {ACM}, address= {New York, NY, USA}}

,
@inproceedings{CVMP2013Arellano, author= {C. Arellano and R. Dahyot}, title= {Robust Bayesian Fitting of 3D Morphable Model}, booktitle= {Proceedings of the 10th European Conference on Visual Media Production}, series= {CVMP '13}, year= {2013}, isbn= {978-1-4503-2589-9}, location= {London, United Kingdom}, pages= {9:1--9:10}, articleno= {9}, numpages= {10}, url= {http://doi.acm.org/10.1145/2534008.2534013}, doi= {http://doi.org/10.1145/2534008.2534013}, acmid= {2534013}, publisher= {ACM}, address= {New York, NY, USA}, keywords= {3D face reconstruction, L2E, RGB-D sensor, computer vision, divergence, morphable models, registration, shape fitting}}

,
@InProceedings{KimMuscle2011, author= {Kim, Donghoon
and Dahyot, Rozenn}, editor= {Salerno, Emanuele
and {\c{C}}etin, A. Enis
and Salvetti, Ovidio}, title= {Bayesian Shape from Silhouettes}, booktitle= {Computational Intelligence for Multimedia Understanding}, year= {2012}, publisher= {Springer Berlin Heidelberg}, address= {Berlin, Heidelberg}, pages= {78--89}, abstract= {This paper extends the likelihood kernel density estimate of the visual hull proposed by Kim et al [1] by introducing a prior. Inference of the shape is performed using a meanshift algorithm over a posterior kernel density function that is refined iteratively using both a multiresolution framework (to avoid local maxima) and using KNN for selecting the best reconstruction basis at each iteration. This approach allows us to recover concave areas of the shape that are usually lost when estimating the visual hull.}, isbn= {978-3-642-32436-9}, doi= {http://doi.org/10.1007/978-3-642-32436-9}}

,
@INPROCEEDINGS{6334154, author= {J. {Ruttle} and C. {Arellano} and R. {Dahyot}}, booktitle= {2012 Proceedings of the 20th European Signal Processing Conference (EUSIPCO)}, title= {Extrinsic camera parameters estimation for shape-from-depths}, year= {2012}, volume= {}, number= {}, pages= {1985-1989}, keywords= {calibration;cameras;correlation methods;image reconstruction;parameter estimation;extrinsic camera parameter estimation;shape-from-depths;3D reconstruction;multiple view images;standard camera calibration techniques;kinect depth camera;recorded depth images;Cameras;Calibration;Cost function;Shape;Probability density function;Computational modeling;Correlation;Shape-from-Silhouettes (SfS);Shape-from-Depths (SfD);Multiview geometry}, ISSN= {2219-5491}, month= {Aug}}

,
@Inproceedings{ISSC2012Ziggy, title= {Feature Selection Using Visual Saliency for Content-Based Image Retrieval}, author= {Z. Zdziarski and R. Dahyot}, booktitle= {23nd IET Irish Signals and Systems Conference}, month= {June, 28-29}, year= {2012}, address= {Maynooth, Ireland}, doi= {https://doi.org/10.1049/ic.2012.0194}, url= {https://ieeexplore.ieee.org/document/6621173/}}

,
@INPROCEEDINGS{6334159, author= {C. {Arellano} and R. {Dahyot}}, booktitle= {2012 Proceedings of the 20th European Signal Processing Conference (EUSIPCO)}, title= {Mean shift algorithm for robust rigid registration between Gaussian Mixture Models}, year= {2012}, volume= {}, number= {}, pages= {1154-1158}, keywords= {Gaussian processes;image registration;image sensors;optical radar;optical scanners;mean shift algorithm;robust rigid registration algorithm;Gaussian mixture models;MS algorithm;rigid point set transformation estimation;Euclidean distance;GMM;annealing framework;density estimation;3D real data sets;lidar scanner;Kinect sensor;Bandwidth;Density functional theory;Robustness;Kernel;Estimation;Annealing;Cost function;Mean Shift;Registration;Gaussian Mixture Models;Rigid Transformation}, ISSN= {2219-5491}, month= {Aug}}

,
@article{IJCV2012Cem, author= {Direkoglu, Cem
and Dahyot, Rozenn
and Manzke, Michael}, title= {On Using Anisotropic Diffusion for Skeleton Extraction}, journal= {International Journal of Computer Vision}, year= {2012}, month= {Nov}, day= {01}, volume= {100}, number= {2}, pages= {170--189}, abstract= {We present a novel and effective skeletonization algorithm for binary and gray-scale images, based on the anisotropic heat diffusion analogy. We diffuse the image in the direction normal to the feature boundaries and also allow tangential diffusion (curvature decreasing diffusion) to contribute slightly. The proposed anisotropic diffusion provides a high quality medial function in the image: it removes noise and preserves prominent curvatures of the shape along the level-sets (skeleton features). The skeleton strength map, which provides the likelihood of a point to be part of the skeleton, is defined by the mean curvature measure. Finally, thin and binary skeleton is obtained by non-maxima suppression and hysteresis thresholding of the skeleton strength map. Our method outperforms the most related and the popular methods in skeleton extraction especially in noisy conditions. Results show that the proposed approach is better at handling noise in images and preserving the skeleton features at the centerline of the shape.}, issn= {1573-1405}, doi= {https://doi.org/10.1007/s11263-012-0540-9}, url= {https://doi.org/10.1007/s11263-012-0540-9}}

,
@Inproceedings{ISSC2012Claudia, title= {Shape Model Fitting Using non-Isotropic GMM}, author= {C. Arellano and R. Dahyot}, booktitle= {IET Irish Signals and Systems Conference (ISSC 2012)}, year= {2012}, month= {June, 28-29}, pages= {1-6}, address= {Maynooth, Ireland}, url= {https://ieeexplore.ieee.org/document/6621175/}, doi= {https://doi.org/10.1049/ic.2012.0196}, keywords= {Gaussian processes;covariance matrices;solid modelling;Euclidean distance;Gaussian kernel;Gaussian mixture density functions;mean shift algorithm;nonisotropic GMM;nonisotropic covariance matrices;posterior density function;shape model fitting;Fitting Algorithm;Gaussian Mixture Models;Mean Shift;Morphable Models}}

,
@Inproceedings{Eusipco2012Arellano1, author= {C. Arellano and R. Dahyot}, booktitle= {2012 Proceedings of the 20th European Signal Processing Conference (EUSIPCO)}, title= {Shape model fitting algorithm without point correspondence}, year= {2012}, volume= {}, number= {}, pages= {934-938}, keywords= {Gaussian processes;shape recognition;2D hand model;3D morphable model;Bayesian framework;Euclidean distance;Gaussian mixture density functions;Gaussian prior;Gaussians mixtures;MS algorithm;mean shift algorithm;shape model fitting algorithm;Computational modeling;Data models;Euclidean distance;Robustness;Shape;Signal processing algorithms;Solid modeling;Gaussian Mixture Models;Mean Shift;Morphable Models;Shape Fitting}, doi= {}, ISSN= {2219-5491}, month= {Aug}, eprint= {https://www.eurasip.org/Proceedings/Eusipco/Eusipco2012/Conference/papers/1569582293.pdf}, url= {https://ieeexplore.ieee.org/document/6333999/}}

,
@article{Risser2010, author= {Risser, Eric and Han, Charles and Dahyot, Rozenn and Grinspun, Eitan}, title= {Synthesizing Structured Image Hybrids}, journal= {ACM Trans. Graph.}, issue_date= {July 2010}, volume= {29}, number= {4}, month= {jul}, year= {2010}, issn= {0730-0301}, pages= {85:1--85:6}, articleno= {85}, numpages= {6}, url= {http://doi.acm.org/10.1145/1778765.1778822}, doi= {https://doi.org/10.1145/1778765.1778822}, acmid= {1778822}, publisher= {ACM}, address= {New York, NY, USA}}

,
@INPROCEEDINGS{Kim2010Icassp, author= {D. Kim and  J. Ruttle and R. Dahyot}, booktitle= {IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP 2010) }, title= {3D shape estimation from silhouettes using Mean-shift}, year= {2010}, month= {March}, volume= {}, number= {}, pages= {1430 -1433}, keywords= {}, doi= {http://doi.org/10.1109/ICASSP.2010.5495474}, ISSN= {1520-6149}}

,
@inbook{LCPC2010, Chapter= {D\'{e}tection et Reconnaissance de la signalisation verticale par analyse d'images}, author= {P. Charbonnier and R. Dahyot and T. Vik and F. Heitz}, title= {Detection et reconnaissance de la signalisation verticale par analyse d’images (Ed: P. Foucher)}, publisher= {Etudes et Recherches des laboratoires des Ponts et Chaussées, CR53 ( ISBN 978-2-7208-2578-1)}, month= {July}, year= {2010}, }
,
@inproceedings{Direkoglu2010, title= {Skeleton Extraction via Anisotropic Heat Flow}, author= {Direkoglu, Cem and Dahyot, Rozenn and Manzke, Michael}, year= {2010}, pages= {61.1--61.11}, booktitle= {Proceedings of the British Machine Vision Conference}, publisher= {BMVA Press}, editors= {Labrosse, Fr\'ed\'eric and Zwiggelaar, Reyer and Liu, Yonghuai and Tiddeman, Bernie}, isbn= {1-901725-40-5}, doi= {http://doi.org/10.5244/C.24.61}}

,
@inproceedings{Ruttle2010CVMP, title= {Smooth Kernel Density Estimate for Multiple View Reconstruction}, author= {J. Ruttle and M. Manzke and R. Dahyot}, booktitle= {proceedings of The 7th European Conference for Visual Media Production, CVMP 2010}, location= {London UK}, month= {17 - 18 November}, pages= {74 -81}, year= {2010}, doi= {http://doi.org/10.1109/CVMP.2010.17}}

,
@inproceedings{Arellano2010, title= {Stereo Images for 3D Face Applications: A Literature Review}, author= {C. Arellano and R. Dahyot}, booktitle= {International Machine Vision and Image Processing Conference (IMVIP 2010)}, address= {Limerick Ireland}, month= {September}, year= {2010}, url= {http://www.cambridgescholars.com/14th-international-machine-vision-and-image-processing-conference-21}}

,
@inproceedings{Kim09IMVIP, title= {3D Head Reconstruction using Multi-camera Stream}, author= {D. Kim and R. Dahyot}, booktitle= {International Machine Vision and Image Processing conference (IMVIP 2009)}, pages= {156-161}, address= {Dublin, Ireland}, month= {September}, year= {2009}, url= {https://ieeexplore.ieee.org/document/5319298/}, doi= {https://doi.org/10.1109/IMVIP.2009.35}}

,
@inproceedings{Ruttle09Imvip, title= {Estimating 3D Scene Flow from Multiple 2D Optical Flows}, author= {J. Ruttle and M. Manzke and R. Dahyot}, booktitle= {International Machine Vision and Image Processing Conference (IMVIP 2009)}, pages= {6-11}, address= {Dublin, Ireland}, month= {September}, year= {2009}, url= {https://ieeexplore.ieee.org/document/5319350/}, doi= {https://doi.org/10.1109/IMVIP.2009.8}}

,
@techreport{Dahyot09TR, title= {Mean-shift for Statistical Hough Transform}, author= {R. Dahyot}, number= {01/09}, institution= {School of Computer Science and Statistics, Trinity College Dublin}, month= {April}, year= {2009}, url= {https://www.scss.tcd.ie/disciplines/statistics/tech-reports/09-01.pdf}}

,
@techreport{Dahyot09TR, title= {Mean-shift for Statistical Hough Transform}, author= {R. Dahyot}, number= {01/09}, institution= {School of Computer Science and Statistics, Trinity College Dublin}, month= {April}, year= {2009}, url= {https://www.scss.tcd.ie/disciplines/statistics/tech-reports/09-01.pdf}}

,
@inproceedings{Zdziarski09Imvip, title= {Robust Panning Analysis for Slideshow Detection in Video Databases}, author= {Z. Zdziarski and R. Dahyot}, booktitle= {International Machine Vision and Image Processing Conference (IMVIP 2009)}, pages= {89-93}, address= {Dublin, Ireland}, month= {September}, year= {2009}, url= {https://ieeexplore.ieee.org/document/5319322/}, doi= {https://doi.org/10.1109/IMVIP.2009.23}}

,
@article{Dahyot08pami, author= {R. Dahyot}, journal= {IEEE Transactions on Pattern Analysis and Machine Intelligence}, title= {Statistical Hough Transform}, year= {2009}, volume= {31}, number= {8}, pages= {1502-1509}, keywords= {Hough transforms;object detection;statistical analysis;continuous kernel estimate;image processing;line detection;spatial domain coordinate;statistical Hough transform;Hough transform;Image Processing and Computer Vision;Radon transform;Transform methods;kernel probability density function;line detection.;uncertainty}, doi= {https://doi.org/10.1109/TPAMI.2008.288}, ISSN= {0162-8828}, month= {Aug}}

,
@inproceedings{Ruttle09Siggraph, author= {J. Ruttle and M. Manzke and M. Prazak and R. Dahyot}, title= {Synchronized real-time multi-sensor motion capture system}, booktitle= {SIGGRAPH ASIA '09: ACM SIGGRAPH ASIA 2009 Posters}, year= {2009}, pages= {1--1}, location= {Yokohama, Japan}, doi= {http://doi.acm.org/10.1145/1666778.1666828}, publisher= {ACM}, address= {New York, NY, USA}}

,
@inproceedings{KearneyAES08, title= {Audio-Visual Processing Tools for Auditory Scene Synthesis}, author= {G. Kearney and R. Dahyot and F. Boland}, booktitle= {Audio Engineering Society 134th Convention}, month= {May}, year= {2008}, url= {http://www.aes.org/e-lib/browse.cfm?elib=14495}}

,
@inproceedings{Dahyoticpr08, title= {Bayesian Classification for the Statistical Hough Transform}, author= {R. Dahyot}, booktitle= {2008 19th International Conference on Pattern Recognition}, month= {December}, address= {Tampa, Florida}, year= {2008}, keywords= {Bayes methods;Hough transforms;Radon transforms;image classification;image segmentation;statistical analysis;2D accumulator histogram;Bayesian classification scheme;image space;inverse Radon transform;kernel mixture;statistical Hough transform;Bandwidth;Bayesian methods;Computer science;Discrete transforms;Educational institutions;Histograms;Image segmentation;Kernel;Robustness;Statistics}, pages= {1 -4}, doi= {https://doi.org/10.1109/ICPR.2008.4761109}, ISSN= {1051-4651}}

,
@inproceedings{Donghoon08imvip, author= {D. Kim and R. Dahyot}, title= {Face components detection using SURF descriptor and SVMs}, booktitle= {International Machine Vision and Image Processing conference (IMVIP 2008)}, year= {2008}, doi= {https://doi.org/10.1109/IMVIP.2008.15}, url= {https://ieeexplore.ieee.org/document/4624384/}}

,
@article{Dahyot08, author= {Dahyot, Rozenn
and Vilari{\~{n}}o, Fernando
and Lacey, Gerard}, title= {Improving the Quality of Color Colonoscopy Videos}, journal= {EURASIP Journal on Image and Video Processing}, year= {2008}, month= {Jan}, day= {22}, volume= {2008}, number= {1}, pages= {139429}, abstract= {Colonoscopy is currently one of the best methods to detect colorectal cancer. Nowadays, one of the widely used colonoscopes has a monochrome chipset recording successively at 60{\thinspace}Hz                                                                          and                                                                          components merged into one color video stream. Misalignments of the channels occur each time the camera moves, and this artefact impedes both online visual inspection by doctors and offline computer analysis of the image data. We propose to restore this artefact by first equalizing the color channels and then performing a robust camera motion estimation and compensation.}, issn= {1687-5281}, doi= {https://doi.org/10.1155/2008/139429}, url= {https://doi.org/10.1155/2008/139429}}

,
@Inbook{Wilson2008, author= {Wilson, Simon P.
and Dahyot, Rozenn
and Cunningham, P{\'a}draig}, chapter= {Introduction to Bayesian Methods and Decision Theory}, title= {Machine Learning Techniques for Multimedia: Case Studies on Organization and Retrieval }, year= {2008}, publisher= {Springer Berlin Heidelberg (Eds: Cord, Matthieu
and Cunningham, P{\'a}draig)}, address= {Berlin, Heidelberg}, pages= {3--19}, abstract= {Bayesian methods are a class of statistical methods that have some appealing properties for solving problems in machine learning, particularly when the process being modelled has uncertain or random aspects. In this chapter we look at the mathematical and philosophical basis for Bayesian methods and how they relate to machine learning problems in multimedia. We also discuss the notion of decision theory, for making decisions under uncertainty, that is closely related to Bayesian methods. The numerical methods needed to implement Bayesian solutions are also discussed. Two specific applications of the Bayesian approach that are often used in machine learning -- na{\"i}ve Bayes and Bayesian networks -- are then described in more detail.}, isbn= {978-3-540-75171-7}, doi= {https://doi.org/10.1007/978-3-540-75171-7{\_1}}, url= {https://doi.org/10.1007/978-3-540-75171-7_1}}

,
@Inbook{DahyotChapter2008, author= {Dahyot, Rozenn
and Piti{\'e}, Fran{\c{c}}ois
and Lennon, Daire
and Harte, Naomi
and Kokaram, Anil}, chapter= {Action Recognition in Multimedia Streams}, title= {Multimodal Processing and Interaction: Audio, Video, Text}, year= {2008}, publisher= {Springer US (Eds: Maragos, Petros and Potamianos, Alexandros and Gros, Patrick)}, address= {Boston, MA}, isbn= {978-0-387-76316-3}, doi= {https://doi.org/10.1007/978-0-387-76316-3{\_}5}, url= {https://doi.org/10.1007/978-0-387-76316-3_5}}

,
@Inbook{PitieCRC2008, title= {Single-Sensor Imaging: Methods and Applications for Digital Cameras}, chapter= {Enhancement of Digital Photographs Using Color Transfer Techniques}, author= {F. Pitie and A. Kokaram and R. Dahyot}, publisher= {CRC Press Image Processing Series, Rastislav Lukac (Ed.) ISBN: 9781420054521}, month= {October}, year= {2008}, doi= {https://doi.org/10.1201/9781420054538.ch11}}

,
@article{Pitie_CVIU2007, title= {Automated colour grading using colour distribution transfer}, journal= {Computer Vision and Image Understanding}, volume= {107}, number= {1}, pages= {123 - 137}, year= {2007}, note= {Special issue on color image processing}, issn= {1077-3142}, doi= {https://doi.org/10.1016/j.cviu.2006.11.011}, url= {http://www.sciencedirect.com/science/article/pii/S1077314206002189}, author= {François Pitié and Anil C. Kokaram and Rozenn Dahyot}, keywords= {Colour grading, Colour transfer, Re-colouring, Distribution transfer}}

,
@techreport{Dahyot07, title= {Statistical Hough Transform}, author= {R. Dahyot}, number= {TCD-CS-2007-37}, institution= {School of Computer Science and Statistics, Trinity College Dublin}, month= {July}, year= {2007}, url= {https://www.cs.tcd.ie/publications/tech-reports/reports.07/TCD-CS-2007-37.pdf}}

,
@inproceedings{Kelly2007, author= {R. Dahyot and C. Kelly and G. Kearney}, title= {Visual enhancement using multiple audio streams in live music performance}, booktitle= {31st International Conference Audio Engineering Society }, year= {2007}, address= {London, UK}, month= {June}}

,
@INPROCEEDINGS{Dahyot_IWSM2006, title= {Bayesian Inferences for Object Detection}, author= {R. Dahyot}, booktitle= {21st International Workshop on Statistical Modelling}, address= {Galway, Ireland}, month= {July 3-7}, pages= {127-130}, year= {2006}}

,
@ARTICLE{Kokaram2006, author= {A. Kokaram and N. Rea and R. Dahyot and M. Tekalp and P. Bouthemy and P. Gros and I. Sezan}, journal= {IEEE Signal Processing Magazine}, title= {Browsing sports video: trends in sports-related indexing and retrieval work}, year= {2006}, volume= {23}, number= {2}, pages= {47-58}, keywords= {content-based retrieval;indexing;sport;video retrieval;automated content-based analysis;content analysis system design;digital media;digital television;interactive viewing experience;retrieval work;semantic-level retrieval system;sports video;sports-based indexing;sports-related indexing;Broadcasting;Cameras;Educational institutions;Games;Image analysis;Indexing;Information retrieval;Multimedia communication;Packaging;Tagging}, doi= {https://doi.org/10.1109/MSP.2006.1621448}, ISSN= {1053-5888}, month= {March}}

,
@inproceedings{Rea2006, author= {N. Rea and C. Lambe and G. Lacey and R. Dahyot}, booktitle= {The 3rd European Conference on Visual Media Production (CVMP 2006) - Part of the 2nd Multimedia Conference 2006}, title= {Multimodal Periodicity Analysis for Illicit Content Detection in Videos}, year= {2006}, volume= {}, number= {}, pages= {106-114}, keywords= {}, doi= {https://doi.org/10.1049/cp:20061978}, eprint= {https://ieeexplore.ieee.org/document/4156017/}, ISSN= {0537-9989}, month= {Nov}}

,
@ARTICLE{Dahyot_MZ2006, title= {Robust Scale Estimation for the generalized Gaussian Probability Density Function}, author= {R. Dahyot and S. Wilson}, journal= {Advances in Methodology and Statistics (Metodolo\v{s}ki zvezki)}, year= {2006}, pages= {21-37}, number= {1}, volume= {3}, url= {\url{https://www.stat-d.si/mz/mz3.1/dahyot.pdf}}}

,
@INPROCEEDINGS{Dahyot_IMVIP06, title= {Unsupervised Camera Motion Estimation and Moving Object Detection in Videos}, author= {R. Dahyot}, booktitle= {Irish Machine Vision and Image Processing conference (IMVIP 2006)}, address= {Dublin, Ireland}, month= {30 Aug.-1 Sept.}, year= {2006}, url= {http://hdl.handle.net/2262/2058}}

,
@INPROCEEDINGS{ReaICIP05, author= {N. Rea and R. Dahyot and A. Kokaram}, booktitle= {IEEE International Conference on Image Processing 2005}, title= {Classification and representation of semantic content in broadcast tennis videos}, year= {2005}, volume= {3}, number= {}, pages= {III-1204-7}, keywords= {image classification;image colour analysis;image representation;image sequences;particle filtering (numerical methods);video signal processing;broadcast tennis videos;particle filter;semantic analysis;spatio-temporal behaviour;video classification;video representation;video sequence;Content based retrieval;Educational institutions;Hidden Markov models;Histograms;Multimedia communication;Particle filters;Particle tracking;Streaming media;TV broadcasting;Videos}, doi= {https://doi.org/10.1109/ICIP.2005.1530614}, ISSN= {1522-4880}, month= {Sept}}

,
@INPROCEEDINGS{KokaramCBMI05, title= {Content Controlled Image Representation for Sports Streaming}, author= {A. Kokaram and F. Piti\'{e} and R. Dahyot and N. Rea and S. Yeterian}, booktitle= {proceedings of the IEEE workshop on Content Based Multimedia Indexing (CBMI'05)}, address= {Riga, Latvia}, month= {June}, year= {2005}}

,
@inproceedings{10.1145/1101826.1101857, author= {Denman, Hugh and Doyle, Erika and Kokaram, Anil and Lennon, Daire and Dahyot, Rozenn and Fuller, Ray}, title= {Exploiting Temporal Discontinuities for Event Detection and Manipulation in Video Streams}, year= {2005}, isbn= {1595932445}, publisher= {Association for Computing Machinery}, address= {New York, NY, USA}, url= {https://doi.org/10.1145/1101826.1101857}, doi= {10.1145/1101826.1101857}, booktitle= {Proceedings of the 7th ACM SIGMM International Workshop on Multimedia Information Retrieval}, pages= {183-192}, numpages= {10}, keywords= {event spotting, video retrieval, motion tracking, information retrieval, bayesian inference}, location= {Hilton, Singapore}, series= {MIR 05}}

,
@Inproceedings{PitieICCV2005, author= {F. Piti\'{e} and A. C. Kokaram and R. Dahyot}, booktitle= {Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1}, title= {N-dimensional probability density function transfer and its application to color transfer}, year= {2005}, volume= {2}, number= {}, pages= {1434-1439 Vol. 2}, keywords= {image colour analysis;probability;1D marginal distribution;automated color grading;color transfer;continuous transformation;probability density function;Color;Computational efficiency;Density functional theory;Distributed computing;Educational institutions;Image converters;Iterative methods;Rendering (computer graphics);Statistical distributions;Statistics}, doi= {https://doi.org/10.1109/ICCV.2005.166}, ISSN= {1550-5499}, month= {Oct}}

,
@INPROCEEDINGS{PitieICIP05, author= {F. Piti\'{e}  and S. A. Berrani and A. Kokaram and R. Dahyot}, booktitle= {IEEE International Conference on Image Processing 2005}, title= {Off-line multiple object tracking using candidate selection and the Viterbi algorithm}, year= {2005}, volume= {3}, number= {}, pages= {III-109-12}, keywords= {maximum likelihood estimation;object detection;particle filtering (numerical methods);Viterbi algorithm;candidate selection;deterministic solution;off-line multiple object tracking;particle filter methods;probabilistic framework;Data mining;Feature extraction;Image sequences;Indexing;Information retrieval;Particle filters;Particle tracking;Performance analysis;Surveillance;Viterbi algorithm}, doi= {https://doi.org/10.1109/ICIP.2005.1530340}, ISSN= {1522-4880}, month= {Sept}}

,
@ARTICLE{Dahyot_PAA, author= {Dahyot, Rozenn
and Charbonnier, Pierre
and Heitz, Fabrice}, title= {A Bayesian approach to object detection using probabilistic appearance-based models}, journal= {Pattern Analysis and Applications}, year= {2004}, month= {Dec}, day= {01}, volume= {7}, number= {3}, pages= {317--332}, abstract= {In this paper, we introduce a Bayesian approach, inspired by probabilistic principal component analysis (PPCA) (Tipping and Bishop in J Royal Stat Soc Ser B 61(3):611--622, 1999), to detect objects in complex scenes using appearance-based models. The originality of the proposed framework is to explicitly take into account general forms of the underlying distributions, both for the in-eigenspace distribution and for the observation model. The approach combines linear data reduction techniques (to preserve computational efficiency), non-linear constraints on the in-eigenspace distribution (to model complex variabilities) and non-linear (robust) observation models (to cope with clutter, outliers and occlusions). The resulting statistical representation generalises most existing PCA-based models (Tipping and Bishop in J Royal Stat Soc Ser B 61(3):611--622, 1999; Black and Jepson in Int J Comput Vis 26(1):63--84, 1998; Moghaddam and Pentland in IEEE Trans Pattern Anal Machine Intell 19(7):696--710, 1997) and leads to the definition of a new family of non-linear probabilistic detectors. The performance of the approach is assessed using receiver operating characteristic (ROC) analysis on several representative databases, showing a major improvement in detection performances with respect to the standard methods that have been the references up to now.}, issn= {1433-755X}, doi= {https://doi.org/10.1007/s10044-004-0230-5}, url= {https://doi.org/10.1007/s10044-004-0230-5}}

,
@INPROCEEDINGS{Pitiesmvp2004, author= {Piti{\'e}, Fran{\c{c}}ois and Dahyot, Rozenn and Kelly, Francis and Kokaram, Anil}, editor= {Comaniciu, Dorin
and Mester, Rudolf
and Kanatani, Kenichi
and Suter, David}, title= {A New Robust Technique for Stabilizing Brightness Fluctuations in Image Sequences}, booktitle= {Statistical Methods in Video Processing}, year= {2004}, publisher= {Springer Berlin Heidelberg}, address= {Berlin, Heidelberg}, pages= {153--164}, abstract= {Temporal random variation of luminance in images can manifest in film and video due to a wide variety of sources. Typical in archived films, it also affects scenes recorded simultaneously with different cameras (e.g. for film special effect), and scenes affected by illumination problems. Many applications in Computer Vision and Image Processing that try to match images (e.g. for motion estimation, stereo vision, etc.) have to cope with this problem. The success of current techniques for dealing with this is limited by the non-linearity of severe distortion, the presence of motion and missing data (yielding outliers in the estimation process) and the lack of fast implementations in reconfigurable systems. This paper proposes a new process for stabilizing brightness fluctuations that improves the existing models. The article also introduces a new estimation method able to cope with outliers in the joint distribution of pairs images. The system implementation is based on the novel use of general purpose PC graphics hardware. The overall system presented here is able to deal with much more severe distortion than previously was the case, and in addition can operate at 7 fps on a 1.6GHz PC with broadcast standard definition images.}, isbn= {978-3-540-30212-4}, doi= {https://doi.org/10.1007/978-3-540-30212-4{\_}14}}

,
@INPROCEEDINGS{Dahyot_IMVIP04, author= {R. Dahyot and A. Kokaram}, title= {Comparison of Two Algorithms for Robust M-estimation of Global Motion Parameters }, booktitle= {Irish Machine Vision and Image Processing conference (IMVIP 2004)}, month= {September}, year= {2004}, pages= {224-231}, address= {Dublin, Ireland}}

,
@INPROCEEDINGS{DahyotMMSP04, author= {R. Dahyot and N. Rea and A. Kokaram and N. Kingsbury}, booktitle= {IEEE 6th Workshop on Multimedia Signal Processing, 2004.}, title= {Inlier modeling for multimedia data analysis}, year= {2004}, volume= {}, number= {}, pages= {482-485}, keywords= {audio signal processing;multimedia communication;normal distribution;audio data segmentation;centred normal distribution;colour class parameter extraction;multimedia data analysis;signal processing;Data analysis;Distributed computing;Educational institutions;Gaussian distribution;Parameter estimation;Parameter extraction;Random variables;Robustness;Signal processing;Statistical distributions}, doi= {https://doi.org/10.1109/MMSP.2004.1436600}, ISSN= {}, month= {Sept}}

,
@INPROCEEDINGS{Rea_ICASSP04, author= {N. Rea and R. Dahyot and A. Kokaram}, booktitle= {2004 IEEE International Conference on Acoustics, Speech, and Signal Processing}, title= {Modeling high level structure in sports with motion driven HMMs}, year= {2004}, volume= {3}, number= {}, pages= {iii-621-4 vol.3}, keywords= {feature extraction;hidden Markov models;image recognition;image retrieval;motion estimation;sport;video signal processing;broadcast sports footage;collision detection;colour based particle filter;dynamic events retrieval;feature extraction;game semantics;hidden Markov model;motion driven HMM;motion extraction;object position evolution modeling;semantic event recognition;snooker ball tracking;snooker table white ball position;sports high level structure modeling;view recognition;view type classification;Broadcasting;Cameras;Educational institutions;Games;Geometry;Hidden Markov models;Interleaved codes;Particle filters;Particle tracking;Video sequences}, doi= {https://doi.org/10.1109/ICASSP.2004.1326621}, ISSN= {1520-6149}, month= {May}}

,
@INPROCEEDINGS{PITIE_IMVIP04, author= {F. Pitie and A. Kokaram and R. Dahyot }, title= {Oriented Particle Spray: A New Probabilistic Contour Tracing with Directional Information}, booktitle= {Irish Machine Vision and Image Processing conference (IMVIP 2004)}, month= {September}, year= {2004}, pages= {158-165}, url= {http://iprcs.org/pdf/IMVIP2004_Proceedings.pdf}, address= {Dublin, Ireland}}

,
@InProceedings{ReaCIVR04, author= {Rea, N.
and Dahyot, R.
and Kokaram, A.}, editor= {Enser, Peter
and Kompatsiaris, Yiannis
and O'Connor, Noel E.
and Smeaton, Alan F.
and Smeulders, Arnold W. M.}, title= {Semantic Event Detection in Sports Through Motion Understanding}, booktitle= {Image and Video Retrieval}, year= {2004}, publisher= {Springer Berlin Heidelberg}, address= {Berlin, Heidelberg}, pages= {88--97}, abstract= {In this paper we investigate the retrieval of semantic events that occur in broadcast sports footage. We do so by considering the spatio-temporal behaviour of an object in the footage as being the embodiment of a particular semantic event. Broadcast snooker footage is used as an example of the sports footage for the purpose of this research. The system parses the sports video using the geometry of the content in view and classifies the footage as a particular view type. A colour based particle filter is then employed to robustly track the snooker balls, in the appropriate view, to evoke the semantics of the event. Over the duration of a player shot, the position of the white ball on the snooker table is used to model the high level semantic structure occurring in the footage. Upon collision of the white ball with another coloured ball, a separate track is instantiated allowing for the detection of pots and fouls, providing additional clues to the event in progress.}, isbn= {978-3-540-27814-6}, doi= {https://doi.org/10.1007/978-3-540-27814-6{\_}14}}

,
@BOOK{B-Dahyot03, author= {Rozenn Dahyot}, title= {Analyse d'images s\'{e}quentielles de sc\`{e}nes routi\`{e}res par mod\`{e}les d'apparence pour la gestion du r\'{e}seau routier}, publisher= {Paris : Laboratoire Central des Ponts et Chaussées (LCPC) 2-7208-2028-1}, series= {Etudes et Recherches des Laboratoires des Ponts et Chaussées}, address= {France}, year= {2003}, month= {September}, note= {(published in french)}}

,
@article{TS2003, title= {Detection robuste par modele probabiliste d apparence : une approche bayesienne }, author= {R. Dahyot and P. Charbonnier and F. Heitz}, journal= {Traitement du Signal}, volume= {20}, number= {2}, pages= {101-117}, year= {2003}, url= {http://hdl.handle.net/2042/2221}}

,
@INPROCEEDINGS{DahyotICASSP03, author= {R. Dahyot and A. Kokaram and N. Rea and H. Denman}, booktitle= {Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP '03). 2003 IEEE International Conference on}, title= {Joint audio visual retrieval for tennis broadcasts}, year= {2003}, volume= {3}, number= {}, pages= {III-561-4 vol.3}, keywords= {audio coding;content-based retrieval;feature extraction;image retrieval;maximum likelihood estimation;principal component analysis;sport;stochastic processes;video coding;PCA;audio features;content retrieval;image features;image moments;joint audio visual retrieval;key episode identification;likelihood approach;scene geometry;sports;stochastic processes;tennis broadcasts;Broadcasting;Content based retrieval;Geometry;Layout;Multimedia communication;Principal component analysis;Robustness;Solid modeling;Stochastic processes;Streaming media}, doi= {https://doi.org/10.1109/ICASSP.2003.1199536}, ISSN= {1520-6149}, month= {April}}

,
@INPROCEEDINGS{Kokaram_VCIP03, title= {Simultaneous Luminance and Position Stabilization for Film and Video}, author= {A. C. Kokaram and R. Dahyot and F. Pitie and H. Denman}, booktitle= {Proc.SPIE Visual Communications and Image Processing}, volume= {5022}, number= {}, pages= {5022 - 5022 - 12}, year= {2003}, doi= {https://doi.org/10.1117/12.476584}, URL= {https://doi.org/10.1117/12.476584}, eprint= {}}

,
@INPROCEEDINGS{Dahyot_VCIP03, author= {Rozenn  Dahyot and Niall  Rea and Anil C. Kokaram}, title= {Sport video shot segmentation and classification}, booktitle= {Proc. SPIE Visual Communications and Image Processing 2003}, volume= {5150}, number= {}, pages= {5150 - 5150 - 10}, year= {2003}, doi= {https://doi.org/10.1117/12.503127}, URL= {https://doi.org/10.1117/12.503127}, eprint= {}}

,
@INPROCEEDINGS{PitieGRETSI2003, 
title= {Suppression du bruit de pompage dans les videos}, 
author= {F. Pitie and R. Dahyot and A. Kokaram}, booktitle= {proceedings of GRETSI conference on signal and image processing}, month= {September}, year= {2003}, address= {Paris, France}, doi= {http://dx.doi.org/2042/13630}, url= {http://hdl.handle.net/2042/13630}}

,
@INPROCEEDINGS{Dahyot_ISS02, author= {P. Delacourt and A. Kokaram and R. Dahyot}, title= {Comparison of Global motion estimators }, booktitle= {proceedings of Irish Signals and Systems Conference}, month= {June}, year= {2002}, address= {Cork, Ireland}}

,
@PHDTHESIS{Dahyot01, author= {Rozenn Dahyot}, title= {Analyse d'images s\'{e}quentielles de sc\`{e}nes routi\`{e}res par mod\`{e}les d'apparence pour la gestion du r\'{e}seau routier (Appearance based road scene video analysis for the management of the road network)}, school= {University of Strasbourg I}, address= {France}, year= {2001}, month= {November}, note= {(published in French)}, eprint= {http://theses.fr/2001STR13130}}

,
@INPROCEEDINGS{Dahyota_gretsi01_event, author= {R. Dahyot and P. Charbonnier and F. Heitz}, title= {D\'{e}tection d'\'{e}v\'{e}nements dans les s\'{e}quences d'images avec cam\'{e}ra  en mouvement}, booktitle= {proceedings of GRETSI conference on signal and image processing}, month= {September}, year= {2001}, address= {Toulouse, France}, doi= {http://dx.doi.org/2042/13333}}

,
@INPROCEEDINGS{Dahyot_gretsi01_robust, author= {R. Dahyot and P. Charbonnier and F. Heitz}, title= {D\'{e}tection robuste d'objets : une approche par modele d'apparence}, booktitle= {proceedings of GRETSI conference on signal and image processing}, month= {September}, year= {2001}, address= {Toulouse, France}, doi= {http://dx.doi.org/2042/13335}}

,
@INPROCEEDINGS{Dahyot_icip01, author= {R. Dahyot and P. Charbonnier and F. Heitz}, booktitle= {Proceedings 2001 International Conference on Image Processing}, title= {Unsupervised statistical detection of changing objects in camera-in-motion video}, year= {2001}, volume= {1}, number= {}, pages= {638-641}, keywords= {feature extraction;image sequences;statistical analysis;backprojection;camera motion;camera-in-motion video;change detection;entering objects;exiting objects;image features;image histograms;image sequences;moving objects;object appearance;road scenes;unsupervised statistical detection;Cameras;Event detection;Gunshot detection systems;Image analysis;Image segmentation;Image sequences;Layout;Motion estimation;Object detection;Production systems}, doi= {https://doi.org/10.1109/ICIP.2001.959126}, ISSN= {}, month= {}}

,
@INPROCEEDINGS{Dahyot_cvpr00, author= {R. Dahyot and P. Charbonnier and F. Heitz}, booktitle= {Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)}, title= {Robust visual recognition of colour images}, year= {2000}, volume= {1}, number= {}, pages= {685-690 vol.1}, keywords= {estimation theory;image recognition;image representation;appearance-based representation;colour images;pattern recognition;robust estimation;visual recognition;weighted least squares;Databases;Electrical capacitance tomography;Equations;Image recognition;Image reconstruction;Image segmentation;Least squares methods;Parameter estimation;Pattern recognition;Robustness}, doi= {https://doi.org/10.1109/CVPR.2000.855886}, ISSN= {1063-6919}, month= {}}

,
@INPROCEEDINGS{Dahyot_cbmi99, author= {R. Dahyot and P. Charbonnier and F. Heitz}, title= {Non-Supervised Robust Visual Recognition of Colour Images  using Half-Quadratic Theory}, booktitle= {proceedings of European Workshop on Content-Based Multimedia Indexing (CBMI)}, month= {October}, year= {1999}, address= {Toulouse, France}}

,
@INPROCEEDINGS{Dahyot_gretsi99, author= {R. Dahyot and P. Charbonnier and F. Heitz}, title= {Reconnaissance robuste non supervis\'{e}e d'images en couleur utilisant la th\'{e}orie semi-quadratique}, booktitle= {proceedings of GRETSI conference on signal and image processing}, volume= {2}, pages= {295-298}, month= {September}, year= {1999}, address= {Vannes, France}, doi= {http://dx.doi.org/2042/12964}}

